{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplab v3+\n",
    "\n",
    "This notebook shows how to train a Deeplab v3+ semantic segmentation model on a custom coco-style data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASCAL VOC trained weights already downloaded to /home/keras/data/weights/deeplabv3_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "from wdeeplab.config import Config\n",
    "import wdeeplab.model as modellib\n",
    "import wdeeplab.utils as utils\n",
    "import wdataset.coco as coco\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "HOME_DIR = '/home/keras'\n",
    "DATA_DIR = os.path.join(HOME_DIR, \"data/shapes\")\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"logs\")\n",
    "WEIGHTS_DIR = os.path.join(HOME_DIR, \"data\")\n",
    "PASCAL_WEIGHTS_PATH = os.path.join(WEIGHTS_DIR, \"weights/deeplabv3_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "if not os.path.exists(PASCAL_WEIGHTS_PATH):\n",
    "    print(\"Downloading PASCAL VOC trained weights to {}\".format(PASCAL_WEIGHTS_PATH))\n",
    "    utils.download_trained_weights(WEIGHTS_DIR)\n",
    "else:\n",
    "    print(\"PASCAL VOC trained weights already downloaded to {}\".format(PASCAL_WEIGHTS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset\n",
    "\n",
    "Organize the dataset using the following structure:\n",
    "\n",
    "\n",
    "    DATA_DIR\n",
    "    │\n",
    "    └───annotations\n",
    "    │   │   instances_<subset><year>.json\n",
    "    │   \n",
    "    └───<subset><year>\n",
    "        │   image021.jpeg\n",
    "        │   image022.jpeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = coco.CocoDataset()\n",
    "dataset_train.load_coco(DATA_DIR, subset=\"shapes_train\", year=\"2018\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_validate = coco.CocoDataset()\n",
    "dataset_validate.load_coco(DATA_DIR, subset=\"shapes_validate\", year=\"2018\")\n",
    "dataset_validate.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  64\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  64\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [64 64  3]\n",
      "INPUT_SHAPE                    [64 64  3]\n",
      "INPUT_SHAPE_OUTPUT_FEATURE_RATIO 16\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                200\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               10.0\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "\n",
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the shapes dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 1 images per GPU. Put multiple images on each\n",
    "    # GPU if the images are small.\n",
    "    # BATCH_SIZE = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes (triangles, circles, and squares)\n",
    "\n",
    "    # Use smaller images for faster training. \n",
    "    IMAGE_MAX_DIM = image_size\n",
    "    IMAGE_MIN_DIM = image_size\n",
    "\n",
    "    STEPS_PER_EPOCH = 200\n",
    "\n",
    "    VALIDATION_STEPS = STEPS_PER_EPOCH / 20\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Load pretrained weights and train in two stages: just heads, then finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.DeepLabThreePlus(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inititalize_weights_with = \"pascal\"  # pascal or last\n",
    "\n",
    "if inititalize_weights_with == \"pascal\":\n",
    "    model.load_weights(PASCAL_WEIGHTS_PATH, by_name=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heads\n",
    "\n",
    "Train just the heads of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/keras/data/shapes/logs/shapes20180517T1930/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "entry_flow_conv1_1     (Conv2D)\n",
      "entry_flow_conv1_1_BN   (BatchNormalization)\n",
      "entry_flow_conv1_2     (Conv2D)\n",
      "entry_flow_conv1_2_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block1_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv1_pointwise   (Conv2D)\n",
      "entry_flow_block1_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block1_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv2_pointwise   (Conv2D)\n",
      "entry_flow_block1_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block1_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_separable_conv3_pointwise   (Conv2D)\n",
      "entry_flow_block1_shortcut   (Conv2D)\n",
      "entry_flow_block1_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block1_shortcut_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block2_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv1_pointwise   (Conv2D)\n",
      "entry_flow_block2_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block2_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv2_pointwise   (Conv2D)\n",
      "entry_flow_block2_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block2_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_separable_conv3_pointwise   (Conv2D)\n",
      "entry_flow_block2_shortcut   (Conv2D)\n",
      "entry_flow_block2_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block2_shortcut_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block3_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv1_pointwise   (Conv2D)\n",
      "entry_flow_block3_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block3_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv2_pointwise   (Conv2D)\n",
      "entry_flow_block3_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "entry_flow_block3_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_separable_conv3_pointwise   (Conv2D)\n",
      "entry_flow_block3_shortcut   (Conv2D)\n",
      "entry_flow_block3_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "entry_flow_block3_shortcut_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_1_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_1_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_1_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_1_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_1_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_1_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_1_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_2_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_2_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_2_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_2_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_2_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_2_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_2_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_3_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_3_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_3_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_3_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_3_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_3_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_3_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_4_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_4_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_4_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_4_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_4_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_4_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_4_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_5_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_5_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_5_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_5_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_5_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_5_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_5_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_6_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_6_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_6_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_6_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_6_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_6_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_6_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_7_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_7_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_7_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_7_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_7_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_7_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_7_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_8_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_8_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_8_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_8_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_8_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_8_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_8_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_9_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_9_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_9_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_9_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_9_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_9_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_9_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_10_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_10_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_10_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_10_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_10_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_10_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_10_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_11_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_11_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_11_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_11_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_11_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_11_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_11_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_12_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_12_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_12_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_12_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_12_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_12_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_12_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_13_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_13_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_13_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_13_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_13_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_13_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_13_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_14_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_14_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_14_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_14_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_14_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_14_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_14_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_15_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_15_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_15_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_15_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_15_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_15_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_15_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_16_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv1_pointwise   (Conv2D)\n",
      "middle_flow_unit_16_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_16_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv2_pointwise   (Conv2D)\n",
      "middle_flow_unit_16_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "middle_flow_unit_16_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "middle_flow_unit_16_separable_conv3_pointwise   (Conv2D)\n",
      "middle_flow_unit_16_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block1_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv1_pointwise   (Conv2D)\n",
      "exit_flow_block1_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block1_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv2_pointwise   (Conv2D)\n",
      "exit_flow_block1_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block1_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_separable_conv3_pointwise   (Conv2D)\n",
      "exit_flow_block1_shortcut   (Conv2D)\n",
      "exit_flow_block1_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block1_shortcut_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv1_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block2_separable_conv1_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv1_pointwise   (Conv2D)\n",
      "exit_flow_block2_separable_conv1_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv2_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block2_separable_conv2_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv2_pointwise   (Conv2D)\n",
      "exit_flow_block2_separable_conv2_pointwise_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv3_depthwise   (DepthwiseConv2D)\n",
      "exit_flow_block2_separable_conv3_depthwise_BN   (BatchNormalization)\n",
      "exit_flow_block2_separable_conv3_pointwise   (Conv2D)\n",
      "exit_flow_block2_separable_conv3_pointwise_BN   (BatchNormalization)\n",
      "aspp1_depthwise        (DepthwiseConv2D)\n",
      "aspp2_depthwise        (DepthwiseConv2D)\n",
      "aspp3_depthwise        (DepthwiseConv2D)\n",
      "aspp1_depthwise_BN     (BatchNormalization)\n",
      "aspp2_depthwise_BN     (BatchNormalization)\n",
      "aspp3_depthwise_BN     (BatchNormalization)\n",
      "image_pooling          (Conv2D)\n",
      "image_pooling_BN       (BatchNormalization)\n",
      "aspp0                  (Conv2D)\n",
      "aspp1_pointwise        (Conv2D)\n",
      "aspp2_pointwise        (Conv2D)\n",
      "aspp3_pointwise        (Conv2D)\n",
      "aspp0_BN               (BatchNormalization)\n",
      "aspp1_pointwise_BN     (BatchNormalization)\n",
      "aspp2_pointwise_BN     (BatchNormalization)\n",
      "aspp3_pointwise_BN     (BatchNormalization)\n",
      "concat_projection      (Conv2D)\n",
      "concat_projection_BN   (BatchNormalization)\n",
      "feature_projection0    (Conv2D)\n",
      "feature_projection0_BN   (BatchNormalization)\n",
      "decoder_conv0_depthwise   (DepthwiseConv2D)\n",
      "decoder_conv0_depthwise_BN   (BatchNormalization)\n",
      "decoder_conv0_pointwise   (Conv2D)\n",
      "decoder_conv0_pointwise_BN   (BatchNormalization)\n",
      "decoder_conv1_depthwise   (DepthwiseConv2D)\n",
      "decoder_conv1_depthwise_BN   (BatchNormalization)\n",
      "decoder_conv1_pointwise   (Conv2D)\n",
      "decoder_conv1_pointwise_BN   (BatchNormalization)\n",
      "custom_logits_semantic   (Conv2D)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: rpn_class_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-46653a4a0f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             layers='all')\n\u001b[0m",
      "\u001b[0;32m~/deeplab/libraries/wdeeplab/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checkpoint Path: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_MOMENTUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplab/libraries/wdeeplab/model.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, learning_rate, momentum)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \"mrcnn_class_loss\", \"mrcnn_bbox_loss\", \"mrcnn_mask_loss\"]\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: rpn_class_loss"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_validate,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "\n",
    "Fine tune lower layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n",
    "Run the model on a random image from the test dataset and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = dataset_train.load_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate the performance of the model on the full test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ((results[0]+1)*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = test[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 'heads'\n",
    "\n",
    "# Pre-defined layer regular expressions\n",
    "layer_regex = {\n",
    "    # all layers but the backbone\n",
    "    \"heads\": r\"(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    # From a specific Resnet stage and up\n",
    "    \"3+\": r\"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"4+\": r\"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\_.*)|(rpn\\_.*)|(fpn\\_.*)\",\n",
    "    # All layers\n",
    "    \"all\": \".*\",\n",
    "}\n",
    "if layers in layer_regex.keys():\n",
    "    layers = layer_regex[layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
