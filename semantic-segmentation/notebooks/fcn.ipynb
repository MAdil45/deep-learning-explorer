{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks for Semantic Segmentation\n",
    "\n",
    "Run in the docker image found in https://github.com/waspinator/deep-learning-explorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "import semantic.coco\n",
    "import semantic.config\n",
    "import semantic.weights\n",
    "import semantic.fcn\n",
    "import semantic.evaluate\n",
    "import semantic.utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "HOME_DIR = '/home/keras'\n",
    "ROOT_DATA_DIR = os.path.join(HOME_DIR, \"data\")\n",
    "WEIGHTS_DIR = os.path.join(HOME_DIR, \"data/weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Your data should be in the [COCO style format](http://cocodataset.org/#download).\n",
    "\n",
    "Organize the dataset using the following structure:\n",
    "\n",
    "```\n",
    "DATA_DIR\n",
    "│\n",
    "└───annotations\n",
    "│   │   instances_<subset><year>.json\n",
    "│   \n",
    "└───<subset><year>\n",
    "    │   image021.jpeg\n",
    "    │   image022.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(ROOT_DATA_DIR, \"shapes.zip\"), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(ROOT_DATA_DIR)\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, \"shapes\")\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = semantic.coco.CocoDataset()\n",
    "dataset_train.load_coco(DATA_DIR, subset=\"shapes_train\", year=\"2018\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_validate = semantic.coco.CocoDataset()\n",
    "dataset_validate.load_coco(DATA_DIR, subset=\"shapes_validate\", year=\"2018\")\n",
    "dataset_validate.prepare()\n",
    "\n",
    "dataset_test = semantic.coco.CocoDataset()\n",
    "dataset_test.load_coco(DATA_DIR, subset=\"shapes_test\", year=\"2018\")\n",
    "dataset_test.prepare()\n",
    "\n",
    "print(dataset_train.class_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesFcnConfig(semantic.config.Config):\n",
    "    \"\"\"Configuration for training on the Shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the Shapes dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"shapes_fcn\"\n",
    "\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DATASET_SAMPLES = len(dataset_train.image_ids)\n",
    "     \n",
    "    STEPS_PER_EPOCH = DATASET_SAMPLES / IMAGES_PER_GPU\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + square, circle, triangle\n",
    "\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    STEPS_PER_EPOCH = 128\n",
    "    VALIDATION_STEPS = int(STEPS_PER_EPOCH / 10)\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 0.003\n",
    "    ENCODER = 'VGG16'\n",
    "    \n",
    "config = ShapesFcnConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = semantic.fcn.FCN(config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inititalize_weights_with = 'imagenet'  # imagenet or last\n",
    "\n",
    "if inititalize_weights_with == 'imagenet':\n",
    "    weights_path = semantic.weights.vgg16_imagenet_weights_path()\n",
    "else:\n",
    "    weights_path = model.find_last()[1]\n",
    "\n",
    "semantic.utils.load_weights(model.keras_model.layers, weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train head\n",
    "\n",
    "Train using only the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_validate,\n",
    "            epochs,\n",
    "            layers='head')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune\n",
    "\n",
    "Train more slowly than before but using more or all the layers. Starts from the previous epoch. For example if you set the train head part above to have 4 epochs and you want to fine tune for 2, set the epochs below to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_validate,\n",
    "            epochs,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "Predict on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_id = np.random.choice(dataset_test.image_ids, 1)[0]\n",
    "image = Image.open(dataset_test.image_reference(test_image_id))\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "im = plt.imshow(prediction, interpolation='none')\n",
    "values = np.unique(prediction.ravel())\n",
    "colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "patches = [ matplotlib.patches.Patch(color=colors[i], label=\"{}\".format(dataset_test.class_info[i]['name'])) for i in values ]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize='x-large')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Get the Mean IoU for each class in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic.evaluate.evaluate(model, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = semantic.utils.result_to_coco(prediction, dataset_test.class_info, config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
