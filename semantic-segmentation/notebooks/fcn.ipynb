{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks for Semantic Segmentation\n",
    "\n",
    "Run in the docker image found in https://github.com/waspinator/deep-learning-explorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "import semantic.coco\n",
    "import semantic.config\n",
    "import semantic.weights\n",
    "import semantic.fcn\n",
    "import semantic.evaluate\n",
    "import semantic.utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "HOME_DIR = '/home/keras'\n",
    "ROOT_DATA_DIR = os.path.join(HOME_DIR, \"data\")\n",
    "WEIGHTS_DIR = os.path.join(HOME_DIR, \"data/weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Your data should be in the [COCO style format](http://cocodataset.org/#download).\n",
    "\n",
    "Organize the dataset using the following structure:\n",
    "\n",
    "```\n",
    "DATA_DIR\n",
    "│\n",
    "└───annotations\n",
    "│   │   instances_<subset><year>.json\n",
    "│   \n",
    "└───<subset><year>\n",
    "    │   image021.jpeg\n",
    "    │   image022.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(ROOT_DATA_DIR, \"shapes.zip\"), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(ROOT_DATA_DIR)\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, \"shapes\")\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = semantic.coco.CocoDataset()\n",
    "dataset_train.load_coco(DATA_DIR, subset=\"shapes_train\", year=\"2018\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_validate = semantic.coco.CocoDataset()\n",
    "dataset_validate.load_coco(DATA_DIR, subset=\"shapes_validate\", year=\"2018\")\n",
    "dataset_validate.prepare()\n",
    "\n",
    "dataset_test = semantic.coco.CocoDataset()\n",
    "dataset_test.load_coco(DATA_DIR, subset=\"shapes_test\", year=\"2018\")\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BATCH_MOMENTUM                 0.9\n",
      "BATCH_SIZE                     32\n",
      "DATASET_SAMPLES                700\n",
      "ENCODER                        VGG16\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 32\n",
      "IMAGE_MAX_DIM                  320\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [320 320   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LR_BASE                        0.0002\n",
      "LR_BASE_BASE                   0.0001\n",
      "LR_POWER                       0.9\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "NAME                           shapes_fcn\n",
      "NUM_CLASSES                    4\n",
      "STEPS_PER_EPOCH                128\n",
      "TRAIN_BN                       False\n",
      "VALIDATION_STEPS               12\n",
      "WEIGHT_DECAY                   5e-05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesFcnConfig(semantic.config.Config):\n",
    "    \"\"\"Configuration for training on the Shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the Shapes dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"shapes_fcn\"\n",
    "\n",
    "    IMAGES_PER_GPU = 32\n",
    "    DATASET_SAMPLES = len(dataset_train.image_ids)\n",
    "     \n",
    "    STEPS_PER_EPOCH = DATASET_SAMPLES / IMAGES_PER_GPU\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + square, circle, triangle\n",
    "\n",
    "    IMAGE_MAX_DIM = 320\n",
    "    STEPS_PER_EPOCH = 128\n",
    "    VALIDATION_STEPS = int(STEPS_PER_EPOCH / 10)\n",
    "    BATCH_MOMENTUM = 0.9\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "    LR_BASE_BASE = 0.0001\n",
    "    LR_POWER = 0.9\n",
    "    WEIGHT_DECAY = 0.0001/2\n",
    "    ENCODER = 'VGG16'\n",
    "    \n",
    "config = ShapesFcnConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = semantic.fcn.FCN(config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inititalize_weights_with = 'imagenet'  # imagenet or last\n",
    "\n",
    "if inititalize_weights_with == 'imagenet':\n",
    "    weights_path = semantic.weights.vgg16_imagenet_weights_path()\n",
    "else:\n",
    "    weights_path = model.find_last()[1]\n",
    "\n",
    "semantic.utils.load_weights(model.keras_model.layers, weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train head\n",
    "\n",
    "Train using only the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Schedule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = semantic.utils.create_learning_rate_schedule(\n",
    "    epochs, config.LR_BASE, config.LR_POWER, mode='step_decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_validate,\n",
    "            learning_schedule,\n",
    "            epochs,\n",
    "            layers='head')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune\n",
    "\n",
    "Train more slowly than before but using more or all the layers. Starts from the previous epoch. For example if you set the train part to have 4 epochs and you want to fine tune for 2, set the epochs below to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Schedule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_schedule = semantic.utils.create_learning_rate_schedule(\n",
    "    epochs, config.LR_BASE/10, config.LR_POWER, mode='step_decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_validate,\n",
    "            learning_schedule,\n",
    "            epochs,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "Predict on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_id = np.random.choice(dataset_test.image_ids, 1)[0]\n",
    "image = Image.open(dataset_test.image_reference(test_image_id))\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "im = plt.imshow(prediction, interpolation='none')\n",
    "values = np.unique(prediction.ravel())\n",
    "colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "patches = [ matplotlib.patches.Patch(color=colors[i], label=\"{}\".format(dataset_test.class_info[i]['name'])) for i in values ]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize='x-large')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Get the Mean IoU for each class in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic.evaluate.evaluate(model, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = semantic.utils.result_to_coco(prediction, dataset_test.class_info, config.IMAGE_MAX_DIM, config.IMAGE_MAX_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 320, 320, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 320, 320, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 160, 160, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 160, 160, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 160, 160, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 80, 80, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 80, 80, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 80, 80, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 80, 80, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 40, 40, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 40, 40, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 40, 40, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 40, 40, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 20, 20, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 20, 20, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 20, 20, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 20, 20, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 10, 10, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_fc6 (Conv2D)             (None, 10, 10, 4096) 102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10, 10, 4096) 0           block5_fc6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5_fc7 (Conv2D)             (None, 10, 10, 4096) 16781312    dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 10, 4096) 0           block5_fc7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "score_feat1 (Conv2D)            (None, 10, 10, 4)    16388       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "score_feat2 (Conv2D)            (None, 20, 20, 4)    2052        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "upscore_feat1 (BilinearUpSampli (None, 20, 20, 4)    0           score_feat1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "scale_feat2 (Lambda)            (None, 20, 20, 4)    0           score_feat2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 20, 20, 4)    0           upscore_feat1[0][0]              \n",
      "                                                                 scale_feat2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "score_feat3 (Conv2D)            (None, 40, 40, 4)    1028        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "upscore_feat2 (BilinearUpSampli (None, 40, 40, 4)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_feat3 (Lambda)            (None, 40, 40, 4)    0           score_feat3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 40, 40, 4)    0           upscore_feat2[0][0]              \n",
      "                                                                 scale_feat3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "upscore_feat3 (BilinearUpSampli (None, 320, 320, 4)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 320, 320, 4)  0           upscore_feat3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 134,280,012\n",
      "Trainable params: 134,280,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = semantic.weights.vgg16_imagenet_weights_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
